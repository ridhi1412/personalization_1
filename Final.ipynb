{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Sampling from large data set for prototype\n",
    "2. Writeup\n",
    "3. Neighborhood based model\n",
    "4. Accuracy/ Ranking metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Loading custom built functions\n",
    "from data_loader import load_spark_df, load_pandas_df, spark_to_sparse\n",
    "from lightfm_model import lightfm_model\n",
    "from model1 import get_best_rank, cross_validation, plot_performance_als\n",
    "from baseline_model import baseline_bias_model\n",
    "\n",
    "# Importing pyspark functins\n",
    "import pyspark\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data \n",
    "\n",
    "We implement a function to cache and load the dataframe from secondary memory to reduce data load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /media/anirudh/Data/Code/Fall 2019/Personalization/project/personalization_1/cache/ml-latest-small_movies.msgpack\n",
      "Loading from /media/anirudh/Data/Code/Fall 2019/Personalization/project/personalization_1/cache/ml-latest-small_ratings.msgpack\n"
     ]
    }
   ],
   "source": [
    "# Setting Directory path\n",
    "base_path = os.getcwd()\n",
    "dir_name = 'ml-latest-small'\n",
    "CACHE_DIR = base_path + '/cache/'\n",
    "DATA_DIR =  base_path + '/data/'\n",
    "\n",
    "# Loading the Data Frames\n",
    "movies_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                file_name='movies', \n",
    "                                use_cache=True,\n",
    "                                DATA_DIR=DATA_DIR,\n",
    "                                CACHE_DIR=CACHE_DIR\n",
    "                               )\n",
    "\n",
    "ratings_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of methods\n",
    "\n",
    "### 2.1 Baseline Method: Bias based model\n",
    "\n",
    "We first fit a bias only model to the data to set a benchmark for baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8720  0.8688  0.8758  0.8754  0.8714  0.8727  0.0026  \n",
      "MAE (testset)     0.6730  0.6707  0.6732  0.6738  0.6727  0.6727  0.0011  \n",
      "Fit time          0.05    0.05    0.04    0.04    0.05    0.05    0.00    \n",
      "Test time         0.06    0.07    0.06    0.07    0.06    0.06    0.00    \n"
     ]
    }
   ],
   "source": [
    "baseline_bias_model(ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model based method using Alternating Least Squares method\n",
    "\n",
    "We build a Matrix Factorization model using ALS method, and iterate over diffrent rank ranges to find the optimal rank\n",
    "\n",
    "#### 2.2.1 Finding best hyperparameter setting using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxIter, [3]) \\\n",
    "            .addGrid(model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(model.rank, [64, 128]) \\\n",
    "            .build()\n",
    "\n",
    "# Finding best parameter combination from cross validation\n",
    "cross_validation(ratings_spark_df, \n",
    "                 model=model, \n",
    "                 evaluator='Regression', \n",
    "                 param_grid=paramGrid, \n",
    "                 k_folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 For diffrent ranks, plotting RMSE and coverage on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pow_two_max_rank = 8\n",
    "\n",
    "ranks = [2**i for i in range(pow_two_max_rank+1)]\n",
    "\n",
    "report_df = get_best_rank(ratings_spark_df, ranks=ranks)\n",
    "\n",
    "plot_performance_als(report_df)\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "1. The training error keeps on decreasing with increased rank, but the test error shows no significant improvement indicating signs of overfitting\n",
    "2. The coverage of items improves with respect to rank\n",
    "3. The time to fit the model takes expontially higher time in correlation with rank\n",
    "\n",
    "Note: We use Catalog Coverage to take into account the number of unique movies that were reccomended to atleast one user as a top choice amonsgt the set of all unique movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LightFM: Light Factorization Model\n",
    "\n",
    "We use LightFM model to find how it performs over over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "lightfm_model(sparse_mat, prec_at_k=10, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Neighborhood based method using Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn(sparse_mat,\n",
    "           num_neighbors=5,\n",
    "           metric='euclidean',\n",
    "           algorithm='auto',\n",
    "           n_neighbors=5):\n",
    "\n",
    "    model_knn = NearestNeighbors(\n",
    "        metric='cosine', algorithm='brute', n_neighbors=5, n_jobs=-1)\n",
    "    model_knn.fit(sparse_mat)\n",
    "    distances, indices = model_knn.kneighbors(sparse_mat)\n",
    "    \n",
    "    return (distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "distances, indices = get_nn(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movies_spark_df.drop('timestamp')\n",
    "\n",
    "df_movies = df.toPandas()\n",
    "hashmap = {\n",
    "            movie: i for i, movie in\n",
    "            enumerate(list(df_movies.set_index('movieId').loc[movie_user_mat.index].title)) # noqa\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
