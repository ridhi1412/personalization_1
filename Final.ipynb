{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Sampling from large data set for prototype\n",
    "2. Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Loading custom built functions\n",
    "from model.nearest_neighbor_model import KNN\n",
    "from model.lightfm_model import lightfm_model\n",
    "from model.baseline_model import baseline_bias_model\n",
    "from model.als_model import get_best_rank, cross_validation, plot_performance_als\n",
    "from utils.data_loader import load_spark_df, load_pandas_df, spark_to_sparse, sample_data_frame\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data \n",
    "\n",
    "We implement a function to cache and load the dataframe from secondary memory to reduce data load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from P:\\rmahajan14\\columbia\\fall 2019\\Personalization\\project_1\\personalization_1/cache/ml-latest-small_movies.msgpack\n",
      "Loading from P:\\rmahajan14\\columbia\\fall 2019\\Personalization\\project_1\\personalization_1/cache/ml-latest-small_ratings.msgpack\n",
      "\n",
      "Sampling DataFrame ...\n",
      "Length before sampling: 100836\n",
      "Length after sampling: 10094\n",
      "Length after thresholding: 10008\n"
     ]
    }
   ],
   "source": [
    "# Setting Directory path\n",
    "base_path = os.getcwd()\n",
    "dir_name = 'ml-latest-small'\n",
    "CACHE_DIR = base_path + '/cache/'\n",
    "DATA_DIR =  base_path + '/data/'\n",
    "\n",
    "# Loading the Data Frames\n",
    "movies_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                file_name='movies', \n",
    "                                use_cache=True,\n",
    "                                DATA_DIR=DATA_DIR,\n",
    "                                CACHE_DIR=CACHE_DIR\n",
    "                               )\n",
    "\n",
    "ratings_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)\n",
    "print('\\nSampling DataFrame ...')\n",
    "ratings_spark_df = sample_data_frame(ratings_spark_df, ratio=0.1, min_user_threshold=5, min_item_threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways we could sample our data. In particular, we implemented and tested 3 sampling methods:\n",
    "\n",
    "The first is raw random sampling, where we simply select a random sample of our data. It is a simple samplin g method, however, we found that it doesn't work well in practice, as we have no thresholding criteria - So by selecting random rows, we are not fine tuning the kind of users, or movies (popular or unpopuolar) we want to sample. Had the users and movies been uniformaly distributed, this would have been okay. But, we see that in our data set, the kinds of users and movies show a lot of hetrogenity, with the number of movies rated by each user, as well as the number of times each movie was rated, varying a lot across users. Therefore, we moved on to more sophisticated sampling technique\n",
    "\n",
    "In the second sampling technique, we first selected a subset of the data based on a threshold. So we initially removed any user who had rated less than 'x' items, as well as any movie which had been rated less than 'y' times. We set x and y to 5. After getting the initial thresholded dataset, we then randomly sampled a fraction of 0.1. \n",
    "\n",
    "In the third technique, we first selected the rows with the top 'a' users, and the rows with the top 'b' movies. After getting those 2 datasets, we performed an inner merge to include only users which are in the top 'a', and movies which are in the top 'b'. From this merged dataset containing the most popular users and movies, we then sampled a fraction of the rows for our final sampled dataset.\n",
    "\n",
    "Having tried all these sampling methods (detailed code in utils/sample.py), we selected method 2 as our final sampling technique. This was because choosing all users/movies abive a certain threshold was more in line with our final objective of building a recommendation system which caters to the needs of everyone, not just users who rate a lot of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of methods\n",
    "\n",
    "### 2.1 Baseline Method: Bias based model\n",
    "\n",
    "We first fit a bias only model to the data to set a benchmark for baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9335  0.9478  0.9470  0.9464  0.9520  0.9453  0.0062  \n",
      "MAE (testset)     0.7309  0.7411  0.7490  0.7397  0.7429  0.7407  0.0058  \n",
      "Fit time          0.02    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "\n",
      "\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_bias_model(ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model based method using Alternating Least Squares method\n",
    "\n",
    "We build a Matrix Factorization model using ALS method, and iterate over different rank ranges to find the optimal rank\n",
    "\n",
    "#### 2.2.1 Finding best hyperparameter setting using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Best Model on Test Set: 1.2794\n",
      "Best Hyper-parameter combination for ALS Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HyperParameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maxIter</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regParam</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rank</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HyperParameter Value\n",
       "0        maxIter     3\n",
       "1       regParam  0.01\n",
       "2           rank   128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxIter, [3]) \\\n",
    "            .addGrid(model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(model.rank, [64, 128]) \\\n",
    "            .build()\n",
    "\n",
    "# Finding best parameter combination from cross validation\n",
    "best_hyper_parameter, best_model = cross_validation(ratings_spark_df, \n",
    "                                                     model=model, \n",
    "                                                     evaluator='Regression', \n",
    "                                                     param_grid=paramGrid, \n",
    "                                                     k_folds=3)\n",
    "\n",
    "print(\"Best Hyper-parameter combination for ALS Model:\")\n",
    "display(best_hyper_parameter)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 For different ranks, plotting RMSE and coverage on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pow_two_max_rank = 8\n",
    "\n",
    "ranks = [2**i for i in range(pow_two_max_rank+1)]\n",
    "\n",
    "report_df = get_best_rank(ratings_spark_df, ranks=ranks)\n",
    "\n",
    "plot_performance_als(report_df)\n",
    "display(report_df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "1. The training error keeps on decreasing with increased rank, but the test error shows no significant improvement indicating signs of overfitting\n",
    "2. The coverage of items improves with respect to rank\n",
    "3. The time to fit the model takes expontially higher time in correlation with rank\n",
    "\n",
    "Note: We use Catalog Coverage to take into account the number of unique movies that were recommended to atleast one user as a top choice amonsgt the set of all unique movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LightFM:\n",
    "\n",
    "We use LightFM model to find how it performs over over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "lightfm_model(sparse_mat, prec_at_k=10, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Neighborhood based method using Nearest Neighbor\n",
    "\n",
    "We use Nearest Neighbor algorithm with z-score normalization of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Defining parameters for Nearest Neighbor model\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "KNN(model=model, df=ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe that the Baseline Bias model performs quite well, and other more sophesiticated models (except lightFM) don't yield significant improvments over it hence the Bias model might be the most suited for production\n",
    "\n",
    "#### We observe that LightFm model has high AUC, meaning it is producing quantifiably quality results."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
