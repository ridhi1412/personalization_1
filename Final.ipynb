{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Sampling from large data set for prototype\n",
    "2. Writeup\n",
    "5. Pretty formatting of Cross Validation best parameter printed in 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Loading custom built functions\n",
    "from nearest_neighbor_model import KNN\n",
    "from lightfm_model import lightfm_model\n",
    "from baseline_model import baseline_bias_model\n",
    "from data_loader import load_spark_df, load_pandas_df, spark_to_sparse\n",
    "from model1 import get_best_rank, cross_validation, plot_performance_als\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data \n",
    "\n",
    "We implement a function to cache and load the dataframe from secondary memory to reduce data load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /media/anirudh/Data/Code/Fall 2019/Personalization/project/personalization_1/cache/ml-latest-small_movies.msgpack\n",
      "Loading from /media/anirudh/Data/Code/Fall 2019/Personalization/project/personalization_1/cache/ml-latest-small_ratings.msgpack\n"
     ]
    }
   ],
   "source": [
    "# Setting Directory path\n",
    "base_path = os.getcwd()\n",
    "dir_name = 'ml-latest-small'\n",
    "CACHE_DIR = base_path + '/cache/'\n",
    "DATA_DIR =  base_path + '/data/'\n",
    "\n",
    "# Loading the Data Frames\n",
    "movies_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                file_name='movies', \n",
    "                                use_cache=True,\n",
    "                                DATA_DIR=DATA_DIR,\n",
    "                                CACHE_DIR=CACHE_DIR\n",
    "                               )\n",
    "\n",
    "ratings_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of methods\n",
    "\n",
    "### 2.1 Baseline Method: Bias based model\n",
    "\n",
    "We first fit a bias only model to the data to set a benchmark for baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bias_model(ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model based method using Alternating Least Squares method\n",
    "\n",
    "We build a Matrix Factorization model using ALS method, and iterate over diffrent rank ranges to find the optimal rank\n",
    "\n",
    "#### 2.2.1 Finding best hyperparameter setting using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxIter, [3]) \\\n",
    "            .addGrid(model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(model.rank, [64, 128]) \\\n",
    "            .build()\n",
    "\n",
    "# Finding best parameter combination from cross validation\n",
    "cross_validation(ratings_spark_df, \n",
    "                 model=model, \n",
    "                 evaluator='Regression', \n",
    "                 param_grid=paramGrid, \n",
    "                 k_folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 For diffrent ranks, plotting RMSE and coverage on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pow_two_max_rank = 8\n",
    "\n",
    "ranks = [2**i for i in range(pow_two_max_rank+1)]\n",
    "\n",
    "report_df = get_best_rank(ratings_spark_df, ranks=ranks)\n",
    "\n",
    "plot_performance_als(report_df)\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "1. The training error keeps on decreasing with increased rank, but the test error shows no significant improvement indicating signs of overfitting\n",
    "2. The coverage of items improves with respect to rank\n",
    "3. The time to fit the model takes expontially higher time in correlation with rank\n",
    "\n",
    "Note: We use Catalog Coverage to take into account the number of unique movies that were recommended to atleast one user as a top choice amonsgt the set of all unique movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LightFM: Light Factorization Model\n",
    "\n",
    "We use LightFM model to find how it performs over over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "lightfm_model(sparse_mat, prec_at_k=10, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Neighborhood based method using Nearest Neighbor\n",
    "\n",
    "We use Nearest Neighbor algorithm with z-score normalization of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9031  0.8984  0.9043  0.8964  0.8910  0.8987  0.0048  \n",
      "MAE (testset)     0.6845  0.6850  0.6859  0.6796  0.6776  0.6825  0.0033  \n",
      "Fit time          0.33    0.27    0.26    0.27    0.25    0.28    0.03    \n",
      "Test time         1.26    1.25    1.29    1.26    1.18    1.25    0.04    \n"
     ]
    }
   ],
   "source": [
    "# Defining parameters for Nearest Neighbor model\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "KNN(model=model, df=ratings_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
