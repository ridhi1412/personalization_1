{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Objective\n",
    "We want to develop a recommendation system catered to the needs of the users, while still being profitable for our business. In our minds, this goal of catering to our users, though not exactly the same, is very hightly correlated with the goal of being a profitable business. If we provide better recommendations, more users will want to come to our website for getting recommendations. Further, the existing users will continue to use our website for their recommendations. If we simply recommend the most popular movies, there will be no novelty, and users would not have any reason to choose our website over another. Hence, we want to make personliazed recommendations, and achieve a high acuraccy for our recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Sampling from large data set for prototype\n",
    "2. Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Loading custom built functions\n",
    "from model.nearest_neighbor_model import KNN\n",
    "from model.lightfm_model import lightfm_model\n",
    "from model.baseline_model import baseline_bias_model\n",
    "from model.als_model import get_best_rank, cross_validation, plot_performance_als\n",
    "from utils.data_loader import load_spark_df, load_pandas_df, spark_to_sparse\n",
    "from utils.sample_df import random_sample, sample_df_threshold, sample_popular_df, sample_df_threshold_use_pandas\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data \n",
    "\n",
    "We implement a function to cache and load the dataframe from secondary memory to reduce data load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from P:\\rmahajan14\\columbia\\fall 2019\\Personalization\\project_1\\personalization_1/cache/ml-20m_movies.msgpack\n",
      "Loading from P:\\rmahajan14\\columbia\\fall 2019\\Personalization\\project_1\\personalization_1/cache/ml-20m_ratings.msgpack\n"
     ]
    }
   ],
   "source": [
    "# Setting Directory path\n",
    "base_path = os.getcwd()\n",
    "dir_name = 'ml-20m'\n",
    "CACHE_DIR = base_path + '/cache/'\n",
    "DATA_DIR =  base_path + '/data/'\n",
    "\n",
    "# Loading the Data Frames\n",
    "movies_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                file_name='movies', \n",
    "                                use_cache=True,\n",
    "                                DATA_DIR=DATA_DIR,\n",
    "                                CACHE_DIR=CACHE_DIR\n",
    "                               )\n",
    "\n",
    "ratings_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)\n",
    "\n",
    "ratings_pandas_df = load_pandas_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)\n",
    "print('\\nSampling DataFrame ...')\n",
    "ratings_spark_df = sample_df_threshold_use_pandas(ratings_pandas_df, n=100000, min_user_threshold=5, min_item_threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways we could sample our data. In particular, we implemented and tested 3 sampling methods:\n",
    "\n",
    "The first is raw random sampling, where we simply select a random sample of our data. It is a simple samplin g method, however, we found that it doesn't work well in practice, as we have no thresholding criteria - So by selecting random rows, we are not fine tuning the kind of users, or movies (popular or unpopuolar) we want to sample. Had the users and movies been uniformaly distributed, this would have been okay. But, we see that in our data set, the kinds of users and movies show a lot of hetrogenity, with the number of movies rated by each user, as well as the number of times each movie was rated, varying a lot across users. Therefore, we moved on to more sophisticated sampling technique\n",
    "\n",
    "In the second sampling technique, we first selected a subset of the data based on a threshold. So we initially removed any user who had rated less than 'x' items, as well as any movie which had been rated less than 'y' times. We set x and y to 5. After getting the initial thresholded dataset, we then randomly sampled a fraction of 0.1. \n",
    "\n",
    "In the third technique, we first selected the rows with the top 'a' users, and the rows with the top 'b' movies. After getting those 2 datasets, we performed an inner merge to include only users which are in the top 'a', and movies which are in the top 'b'. From this merged dataset containing the most popular users and movies, we then sampled a fraction of the rows for our final sampled dataset.\n",
    "\n",
    "Having tried all these sampling methods (detailed code in utils/sample.py), we selected method 2 as our final sampling technique. This was because choosing all users/movies abive a certain threshold was more in line with our final objective of building a recommendation system which caters to the needs of everyone, not just users who rate a lot of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of methods\n",
    "\n",
    "### 2.1 Baseline Method: Bias based model\n",
    "\n",
    "We first fit a bias only model to the data to set a benchmark for baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_bias_model(ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model based method using Alternating Least Squares method\n",
    "\n",
    "We build a Matrix Factorization model using ALS method, and iterate over different rank ranges to find the optimal rank\n",
    "\n",
    "#### 2.2.1 Finding best hyperparameter setting using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxIter, [3]) \\\n",
    "            .addGrid(model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(model.rank, [64, 128]) \\\n",
    "            .build()\n",
    "\n",
    "# Finding best parameter combination from cross validation\n",
    "best_hyper_parameter, best_model = cross_validation(ratings_spark_df, \n",
    "                                                     model=model, \n",
    "                                                     evaluator='Regression', \n",
    "                                                     param_grid=paramGrid, \n",
    "                                                     k_folds=3)\n",
    "\n",
    "print(\"Best Hyper-parameter combination for ALS Model:\")\n",
    "display(best_hyper_parameter)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 For different ranks, plotting RMSE and coverage on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pow_two_max_rank = 8\n",
    "\n",
    "ranks = [2**i for i in range(pow_two_max_rank+1)]\n",
    "\n",
    "report_df = get_best_rank(ratings_spark_df, ranks=ranks)\n",
    "\n",
    "plot_performance_als(report_df)\n",
    "display(report_df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "1. The training error keeps on decreasing with increased rank, but the test error shows no significant improvement indicating signs of overfitting\n",
    "2. The coverage of items improves with respect to rank\n",
    "3. The time to fit the model takes expontially higher time in correlation with rank\n",
    "\n",
    "Note: We use Catalog Coverage to take into account the number of unique movies that were recommended to atleast one user as a top choice amongst the set of all unique movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "# 0\tmaxIter\t3\n",
    "# 1\tregParam\t0.01\n",
    "# 2\trank\t128\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LightFM:\n",
    "\n",
    "We use LightFM model to find how it performs over over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "lightfm_model(sparse_mat, prec_at_k=10, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Neighborhood based method using Nearest Neighbor\n",
    "\n",
    "We use Nearest Neighbor algorithm with z-score normalization of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Defining parameters for Nearest Neighbor model\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "KNN(model=model, df=ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe that the Baseline Bias model performs quite well, and other more sophesiticated models (except lightFM) don't yield significant improvments over it hence the Bias model might be the most suited for production\n",
    "\n",
    "#### We observe that LightFm model has high AUC, meaning it is producing quantifiably quality results."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
