{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Sampling from large data set for prototype\n",
    "2. Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Loading custom built functions\n",
    "from model.nearest_neighbor_model import KNN\n",
    "from model.lightfm_model import lightfm_model\n",
    "from model.baseline_model import baseline_bias_model\n",
    "from model.als_model import get_best_rank, cross_validation, plot_performance_als\n",
    "from utils.data_loader import load_spark_df, load_pandas_df, spark_to_sparse, sample_data_frame\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data \n",
    "\n",
    "We implement a function to cache and load the dataframe from secondary memory to reduce data load time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Directory path\n",
    "base_path = os.getcwd()\n",
    "dir_name = 'ml-20m'\n",
    "CACHE_DIR = base_path + '/cache/'\n",
    "DATA_DIR =  base_path + '/data/'\n",
    "\n",
    "# Loading the Data Frames\n",
    "movies_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                file_name='movies', \n",
    "                                use_cache=True,\n",
    "                                DATA_DIR=DATA_DIR,\n",
    "                                CACHE_DIR=CACHE_DIR\n",
    "                               )\n",
    "\n",
    "ratings_spark_df = load_spark_df(dir_name=dir_name, \n",
    "                                 file_name='ratings', \n",
    "                                 use_cache=True,\n",
    "                                 DATA_DIR=DATA_DIR,\n",
    "                                 CACHE_DIR=CACHE_DIR)\n",
    "\n",
    "ratings_spark_df = sample_data_frame(ratings_spark_df, ratio=0.0001, min_user_threshold=5, min_item_threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis of methods\n",
    "\n",
    "### 2.1 Baseline Method: Bias based model\n",
    "\n",
    "We first fit a bias only model to the data to set a benchmark for baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_bias_model(ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model based method using Alternating Least Squares method\n",
    "\n",
    "We build a Matrix Factorization model using ALS method, and iterate over diffrent rank ranges to find the optimal rank\n",
    "\n",
    "#### 2.2.1 Finding best hyperparameter setting using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creating a Parameter Grid for ALS\n",
    "model = ALS(userCol=\"userId\",\n",
    "                  itemCol=\"movieId\",\n",
    "                  ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\",\n",
    "                  nonnegative=True)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxIter, [3]) \\\n",
    "            .addGrid(model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(model.rank, [64, 128]) \\\n",
    "            .build()\n",
    "\n",
    "# Finding best parameter combination from cross validation\n",
    "best_hyper_parameter, best_model = cross_validation(ratings_spark_df, \n",
    "                                                     model=model, \n",
    "                                                     evaluator='Regression', \n",
    "                                                     param_grid=paramGrid, \n",
    "                                                     k_folds=3)\n",
    "\n",
    "print(\"Best Hyper-parameter combination for ALS Model:\")\n",
    "display(best_hyper_parameter)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 For diffrent ranks, plotting RMSE and coverage on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pow_two_max_rank = 8\n",
    "\n",
    "ranks = [2**i for i in range(pow_two_max_rank+1)]\n",
    "\n",
    "report_df = get_best_rank(ratings_spark_df, ranks=ranks)\n",
    "\n",
    "plot_performance_als(report_df)\n",
    "display(report_df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "1. The training error keeps on decreasing with increased rank, but the test error shows no significant improvement indicating signs of overfitting\n",
    "2. The coverage of items improves with respect to rank\n",
    "3. The time to fit the model takes expontially higher time in correlation with rank\n",
    "\n",
    "Note: We use Catalog Coverage to take into account the number of unique movies that were recommended to atleast one user as a top choice amonsgt the set of all unique movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LightFM:\n",
    "\n",
    "We use LightFM model to find how it performs over over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sparse_mat = spark_to_sparse(ratings_spark_df)\n",
    "lightfm_model(sparse_mat, prec_at_k=10, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Neighborhood based method using Nearest Neighbor\n",
    "\n",
    "We use Nearest Neighbor algorithm with z-score normalization of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Defining parameters for Nearest Neighbor model\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "KNN(model=model, df=ratings_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe that the Baseline Bias model performs quite well, and other more sophesiticated models (except lightFM) don't yield significant improvments over it hence the Bias model might be the most suited for production\n",
    "\n",
    "#### We observe that LightFm model has high AUC, meaning it is producing quantifiably quality results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
